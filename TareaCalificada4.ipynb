{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubbims/TareaCalificada3/blob/main/TareaCalificada4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq_-jS9HtUU-"
      },
      "source": [
        "<center><img src=\"https://i.imgur.com/zRrFdsf.png\" width=\"700\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cCaZ1r2tUVA"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/CienciaDeDatosEspacial/intro_geodataframe/blob/main/index.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# The Geo Dataframe\n",
        "\n",
        "The geodataframe (GDF) is a dataframe (DF) where every row represents an spatial element (point, line, polygon).\n",
        "\n",
        "Historically, the most common file type that stores spatial elements is the shapefile. Let's take a look at some of them:\n",
        "\n",
        "1. In GitHub (cloud), create a repository named: introgeodf.\n",
        "2. Clone that repo to a local folder in your computer.\n",
        "3. In that local folder in your computer, create a folder named **maps**.\n",
        "4. Go to **Paidea** and download three compressed files from the folder **WorldMaps**.\n",
        "5. Download those files into the folder **maps** in your computer: *countries*, *cities*, and *rivers*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhGJmen1tUVB"
      },
      "source": [
        "You may see something like this:\n",
        "\n",
        "<img src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/mapsFolderImage.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBs3ovRstUVB"
      },
      "source": [
        "You can decompress those files:\n",
        "\n",
        "<img title=\"a title\" alt=\"Alt text\" src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/folderRar_1.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzvFDa2JtUVB"
      },
      "source": [
        "Now, take a look a **World_Countries**:\n",
        "\n",
        "<img src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/imageCountries_shp.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUOIWMOTtUVB"
      },
      "source": [
        "There, you see that this **one map** requires **several files**. That is the nature of the shapefile.\n",
        "\n",
        "Let's read the file with the help of **geopandas**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJV5G0POtUVB"
      },
      "outputs": [],
      "source": [
        "import os, geopandas as gpd\n",
        "\n",
        "countries=gpd.read_file(os.path.join(\"maps\",\"World_Countries\",\"World_Countries.shp\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5AOj3mktUVC"
      },
      "source": [
        "Let's use some familiar DF functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTVBGfNatUVC"
      },
      "outputs": [],
      "source": [
        "# what is it?\n",
        "type(countries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkvWskZytUVC"
      },
      "outputs": [],
      "source": [
        "# dimensions\n",
        "countries.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETJdBBR1tUVD"
      },
      "outputs": [],
      "source": [
        "# names\n",
        "countries.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrbZt4g5tUVD"
      },
      "outputs": [],
      "source": [
        "# some content\n",
        "countries.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPHdGEtatUVD"
      },
      "outputs": [],
      "source": [
        "# any missing values?\n",
        "countries[countries.isna().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWXmBv-vtUVD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# types\n",
        "countries.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzT4ctrjtUVD"
      },
      "source": [
        "As you see, those pandas commands are working fine, but now we have a new column type: **geometry**. Let's see this map of countries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjMj9myHtUVD"
      },
      "outputs": [],
      "source": [
        "countries.plot(facecolor=\"azure\",#color of polygon fill\n",
        "               edgecolor='black', #color of lines\n",
        "               linewidth=0.1) #thickness of lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCtifGnqtUVD"
      },
      "source": [
        "Let's open the other maps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPbJ4wFHtUVD"
      },
      "outputs": [],
      "source": [
        "rivers=gpd.read_file(os.path.join(\"maps\",\"World_Hydrography\",\"World_Hydrography.shp\"))\n",
        "cities=gpd.read_file(os.path.join(\"maps\",\"World_Cities\",\"World_Cities.shp\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNMiacK4pwfT"
      },
      "source": [
        "This is the rivers map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Gap_au4tUVD"
      },
      "outputs": [],
      "source": [
        "rivers.plot(edgecolor='blue',\n",
        "            linewidth=1,\n",
        "            linestyle='dotted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHVze16QpwfU"
      },
      "source": [
        "This is the cities map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nAC2GkptUVD"
      },
      "outputs": [],
      "source": [
        "cities.plot(marker='.', # marker type\n",
        "            color='red',\n",
        "            markersize=1,\n",
        "            alpha=0.3) # transparency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOiFM3uYtUVE"
      },
      "source": [
        "You can start by creating the layer on the back (the base), and add layers on top:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqkVAvHstUVE"
      },
      "outputs": [],
      "source": [
        "base = countries.plot(facecolor=\"white\",\n",
        "                      edgecolor='black',\n",
        "                      linewidth=0.1,\n",
        "                      figsize=(12,12))\n",
        "\n",
        "rivers.plot(edgecolor='blue', linewidth=0.4,\n",
        "            ax=base)# on top of...\n",
        "cities.plot(marker='.', color='red', markersize=1,alpha=0.7,\n",
        "            ax=base) # on top of...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jjTpWrXpwfU"
      },
      "source": [
        "Saving into a different format (not shapefile):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19HTl43bpwfU"
      },
      "outputs": [],
      "source": [
        "countries.to_file(os.path.join(\"maps\",\"worldMaps.gpkg\"), layer='countries', driver=\"GPKG\")\n",
        "rivers.to_file(os.path.join(\"maps\",\"worldMaps.gpkg\"), layer='rivers', driver=\"GPKG\")\n",
        "cities.to_file(os.path.join(\"maps\",\"worldMaps.gpkg\"), layer='cities', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZgVLj9npwfU"
      },
      "source": [
        "## Geo Merging\n",
        "\n",
        "The countries map has no interesting information beyond the geometry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFknVbWWpwfU"
      },
      "outputs": [],
      "source": [
        "countries.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgNC7vwhpwfV"
      },
      "source": [
        "Let add some information to each country:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RndsAKsipwfV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "fragilityCiaLink=\"https://github.com/CienciaDeDatosEspacial/merging/raw/main/FragilityCia_isos.csv\"\n",
        "\n",
        "fragilityCia=pd.read_csv(fragilityCiaLink)\n",
        "\n",
        "fragilityCia.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1atPNot-pwfV"
      },
      "source": [
        "We want to add the _fragilityCia_ data into the map. That is the merging process.\n",
        "For that, we need a common column. The _Country_ column is the option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsLsMM5LpwfV"
      },
      "outputs": [],
      "source": [
        "# to upper case.\n",
        "countries['COUNTRY']=countries.COUNTRY.str.upper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wp_M_2WpwfV"
      },
      "source": [
        "It is very unlikely the names are written the same. Verify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOy5LtWApwfV"
      },
      "outputs": [],
      "source": [
        "onlyFragilCia=set(fragilityCia.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragilityCia.Country)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpKHnex5pwfV"
      },
      "source": [
        "Check here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iw_FnovSpwfV"
      },
      "outputs": [],
      "source": [
        "onlyFragilCia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjKgn6QSpwfV"
      },
      "outputs": [],
      "source": [
        "# and here\n",
        "onlyMap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiHwZJDkpwfW"
      },
      "source": [
        "## Fuzzy merging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiH0iLTzpwfW"
      },
      "source": [
        "Let's find similar names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fdyKaKTpwfZ"
      },
      "outputs": [],
      "source": [
        "from thefuzz import process\n",
        "\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klPHl1pdpwfZ"
      },
      "outputs": [],
      "source": [
        "# subsetting\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia)\n",
        " if process.extractOne(country,onlyMap)[1]>=90]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tABBHqNFpwfZ"
      },
      "source": [
        "Preparing a _dict_ of changes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIolQdg0pwfa"
      },
      "outputs": [],
      "source": [
        "# then:\n",
        "try1={country: process.extractOne(country,onlyMap)[0] for country in sorted(onlyFragilCia)\n",
        " if process.extractOne(country,onlyMap)[1]>=90}\n",
        "try1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgke-gfhpwfa"
      },
      "source": [
        "Making changes and updating:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CebK60-vpwfa"
      },
      "outputs": [],
      "source": [
        "fragilityCia.replace(to_replace={'Country':try1},inplace=True)\n",
        "\n",
        "# updating\n",
        "onlyFragilCia=set(fragilityCia.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragilityCia.Country)\n",
        "# new matches\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_YqG4ORpwfa"
      },
      "outputs": [],
      "source": [
        "# some manual\n",
        "\n",
        "countries[countries.COUNTRY.str.contains('LAO|ESW|SWA')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz9OlbBqpwfa"
      },
      "outputs": [],
      "source": [
        "manualChanges={'SWAZILAND':'ESWATINI','LAOS':\"LAO PEOPLE'S DEMOCRATIC REPUBLIC (THE)\"}\n",
        "\n",
        "countries.replace(to_replace={'COUNTRY':manualChanges},inplace=True)\n",
        "\n",
        "# updating\n",
        "onlyFragilCia=set(fragilityCia.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragilityCia.Country)\n",
        "# new matches\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K442rQb8pwfa"
      },
      "outputs": [],
      "source": [
        "# then:\n",
        "try2={country: process.extractOne(country,onlyMap)[0] for country in sorted(onlyFragilCia)}\n",
        "try2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_w0tNI0pwfa"
      },
      "outputs": [],
      "source": [
        "# changing\n",
        "fragilityCia.replace(to_replace={'Country':try2},inplace=True)\n",
        "\n",
        "# new update\n",
        "onlyFragilCia=set(fragilityCia.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragilityCia.Country)\n",
        "\n",
        "# new matches\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi-szmCppwfa"
      },
      "source": [
        "We can not improve the situation.\n",
        "\n",
        "Now, when you merge a GDF with a DF, **the GDF has to be on the left**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H9vzEfRpwfb"
      },
      "outputs": [],
      "source": [
        "theMapAndData=countries.merge(fragilityCia,left_on='COUNTRY', right_on='Country')\n",
        "\n",
        "theMapAndData.drop(columns=['Country'],inplace=True) # no need for this column\n",
        "# here it is (new map):\n",
        "theMapAndData.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQeSd8sfpwfb"
      },
      "source": [
        "# Choropleths\n",
        "\n",
        "## Transformation of data values\n",
        "\n",
        "### Re Scaling\n",
        "\n",
        "We should plan how to color the polygons based on some variable, let me check our variables of interest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW1wMHNDpwfb"
      },
      "outputs": [],
      "source": [
        "DataNames=['fragility', 'co2', 'ForestRev_gdp']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y407ahmjpwfb"
      },
      "outputs": [],
      "source": [
        "\n",
        "pd.melt(theMapAndData[DataNames])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZuF9A1Ppwfb"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.displot(pd.melt(theMapAndData[DataNames]),\n",
        "            x=\"value\", hue=\"variable\",kind=\"kde\",\n",
        "            log_scale=(False,False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrLmSKtvpwfb"
      },
      "source": [
        "The variables are in different units, we should try a data rescaling strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq6HfRLVpwfb"
      },
      "outputs": [],
      "source": [
        "# !pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvEIGAa9pwfb"
      },
      "source": [
        "* **StandardScaler**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3hdjG3jpwfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "normalized_data = scaler.fit_transform(theMapAndData[DataNames])\n",
        "sns.displot(pd.melt(pd.DataFrame(normalized_data,columns=DataNames)),\n",
        "            x=\"value\", hue=\"variable\",kind=\"kde\",\n",
        "            log_scale=(False,False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHLbvb8Gpwfc"
      },
      "source": [
        "* **MinMaxScaler**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnnjYiHDpwfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data=scaler.fit_transform(theMapAndData[DataNames])\n",
        "\n",
        "sns.displot(pd.melt(pd.DataFrame(scaled_data,columns=DataNames)),\n",
        "            x=\"value\", hue=\"variable\",kind=\"kde\",\n",
        "            log_scale=(False,False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKstz4HUpwfc"
      },
      "source": [
        "* **RobustScaler**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn-effgDpwfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "robScaled_data = scaler.fit_transform(theMapAndData[DataNames])\n",
        "\n",
        "sns.displot(pd.melt(pd.DataFrame(robScaled_data,columns=DataNames)),\n",
        "            x=\"value\", hue=\"variable\",kind=\"kde\",\n",
        "            log_scale=(False,False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M2uHEuapwfc"
      },
      "source": [
        "* **QuantileTransformer**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDq9cKr_pwfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import QuantileTransformer\n",
        "scaler = QuantileTransformer(n_quantiles=99, random_state=0,output_distribution='normal') #or 'uniform'\n",
        "QtScaled_data = scaler.fit_transform(theMapAndData[DataNames])\n",
        "\n",
        "sns.displot(pd.melt(pd.DataFrame(QtScaled_data,columns=DataNames)),\n",
        "            x=\"value\", hue=\"variable\",kind=\"kde\",\n",
        "            log_scale=(False,False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU4UxMPtpwfc"
      },
      "outputs": [],
      "source": [
        "theMapAndData['fragility_Qt']=QtScaled_data[:,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPtL_8whpwfc"
      },
      "source": [
        "### Discretizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olbainO7pwfd"
      },
      "source": [
        "I will keep the _data_Qt_ data frame. Now, I want cut the data.\n",
        "Please install [**numba**](https://numba.readthedocs.io/en/stable/user/installing.html) before runing the next code; also make sure you have **pysal**, **mapclassify** and **numpy** installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au37cj29pwfd"
      },
      "outputs": [],
      "source": [
        "! pip show numba mapclassify numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaRFH3pfpwfd"
      },
      "source": [
        "Let me discretize **fragility_Qt**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xpUBgCRpwfd"
      },
      "outputs": [],
      "source": [
        "import mapclassify\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(12345) # so we all get the same results!\n",
        "\n",
        "# let's try 5 intervals\n",
        "K=5\n",
        "theVar=theMapAndData.fragility_Qt\n",
        "# same interval width, easy interpretation\n",
        "ei5 = mapclassify.EqualInterval(theVar, k=K)\n",
        "# same interval width based on standard deviation, easy - but not as the previous one, poor when high skewness\n",
        "msd = mapclassify.StdMean(theVar)\n",
        "# interval width varies, counts per interval are close, not easy to grasp, repeated values complicate cuts\n",
        "q5=mapclassify.Quantiles(theVar,k=K)\n",
        "\n",
        "# based on similarity, good for multimodal data\n",
        "mb5 = mapclassify.MaximumBreaks(theVar, k=K)\n",
        "# based on similarity, good for skewed data\n",
        "ht = mapclassify.HeadTailBreaks(theVar) # no K needed\n",
        "# based on similarity, optimizer\n",
        "fj5 = mapclassify.FisherJenks(theVar, k=K)\n",
        "# based on similarity, optimizer\n",
        "jc5 = mapclassify.JenksCaspall(theVar, k=K)\n",
        "# based on similarity, optimizer\n",
        "mp5 = mapclassify.MaxP(theVar, k=K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4CkJa5apwfd"
      },
      "source": [
        "How can we select the right classification?\n",
        "Let me use the the Absolute deviation around class median (ADCM) to make the comparisson:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5JZ4lA6pwfd"
      },
      "outputs": [],
      "source": [
        "class5 = ei5,msd, q5,mb5,  ht, fj5, jc5, mp5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([ c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms['classifier'] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = ['ADCM', 'Classifier']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHpDaNVQpwfd"
      },
      "source": [
        "Now, plot the **adcms**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-SL-WpCpwfd"
      },
      "outputs": [],
      "source": [
        "adcms.sort_values('ADCM').plot.barh(x='Classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syNq2DHvpwfe"
      },
      "source": [
        "Let's save the best strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHVxouE6pwfe"
      },
      "outputs": [],
      "source": [
        "theMapAndData['fragility_Qt_jc5'] = jc5.yb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntxzi9jLpwfe"
      },
      "outputs": [],
      "source": [
        "# there you are\n",
        "theMapAndData[['fragility_Qt','fragility_Qt_jc5']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvZyxkkTpwfe"
      },
      "source": [
        "Let's check the mean of 'fragility_Qt' by the labels of the columns created (from '0' to '4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOQv5hbtpwfe"
      },
      "outputs": [],
      "source": [
        "indexList=['fragility_Qt_jc5']\n",
        "aggregator={'fragility_Qt': ['mean']}\n",
        "\n",
        "pd.concat([theMapAndData[['fragility_Qt',col]].groupby(col,as_index=False).agg(aggregator) for col in indexList],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLf5ltRmpwfe"
      },
      "source": [
        "We could create a new column:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU0aJrvWpwfe"
      },
      "outputs": [],
      "source": [
        "# renaming\n",
        "newLabelsForLevels={0:\"0_Great\", 1:\"1_Good\", 2:\"2_Middle\", 3:\"3_Bad\", 4:\"4_Poor\"}\n",
        "\n",
        "theMapAndData['fragility_Qt_jc5_cat']=theMapAndData.loc[:,'fragility_Qt_jc5'].replace(newLabelsForLevels)\n",
        "\n",
        "# we have\n",
        "theMapAndData[['fragility_Qt','fragility_Qt_jc5','fragility_Qt_jc5_cat']].head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLOFfImXpwfe"
      },
      "source": [
        "We are ready for a choropleth:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dLbwTVvpwff"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='fragility_Qt_jc5_cat', # variable to plot\n",
        "                   cmap='viridis', # set of colors\n",
        "                   categorical=True, # can be interpreted as category\n",
        "                   edgecolor='white', # border color\n",
        "                   linewidth=0., # width of border\n",
        "                   alpha=1, # level of transparency (0 is invisible)\n",
        "                   legend=True, # need a legend?\n",
        "                   # location of legend: 'best', 'upper right', 'upper left', 'lower left',\n",
        "                   # 'lower right', 'right', 'center left', 'center right',\n",
        "                   # 'lower center', 'upper center', 'center'\n",
        "                   legend_kwds={'loc':\"lower left\"},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3OmpDbopwff"
      },
      "source": [
        "However, once you know the ADCM, you can request the choropleth without creating a variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWX-EWRupwff"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='fragility_Qt',\n",
        "                   cmap='OrRd',\n",
        "                   scheme=\"jenkscaspall\",k=5,\n",
        "        edgecolor='grey',\n",
        "        linewidth=0.5,\n",
        "        alpha=1,\n",
        "        legend=True,\n",
        "        legend_kwds={'loc':3},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rakwhXLupwff"
      },
      "outputs": [],
      "source": [
        "# finally\n",
        "\n",
        "theMapAndData.to_file(os.path.join(\"maps\",\"worldMaps.gpkg\"), layer='indicators', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLgwp0Nlpwff"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "<div class=\"alert-success\">\n",
        "\n",
        "1. Transform the co2 and forest variables.\n",
        "2. Discretize the result chosen.\n",
        "3. Make the maps for the co2 and forest variables.\n",
        "4. Add another variable (merge) from the web (or any other source). Transform it , discretize it, and map it.\n",
        "   \n",
        "    \n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {
      "attach-environment": true,
      "summary": "test"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "toc-autonumbering": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}